{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import pdb; \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify a image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = Path(os.getcwd()).parent.parent.parent/'Data'/'houses/resize256jpg'\n",
    "\n",
    "#test\n",
    "assert os.path.isdir(IMAGE_FOLDER), str(str(IMAGE_FOLDER) + \" is not an existing directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLABELED_TAG = \"UNLABELED\"\n",
    "IGNORE_TAG = \"IGNORE\"\n",
    "\n",
    "ATTRIBUTES = {\n",
    "    \"house_color\":[\"WhiteGreyHouse\",\"BrownHouse\",\"BrickHouse\",\"RedPinkOrangeHouse\",\"BlueHouse\",\"MixedHouse\"],\n",
    "    \"fence_type\":[\"WhitePicketFence\",\"BlackFence\",\"NoFence\",\"ChainFence\",\"BrownFence\"],\n",
    "    \"steps_up\":[\"NoSteps\",\"Steps\",\"LargePorch\"]\n",
    "}\n",
    "for key in ATTRIBUTES.keys():\n",
    "    ATTRIBUTES[key].append(IGNORE_TAG)\n",
    "    ATTRIBUTES[key].append(UNLABELED_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify a CSV (existing or not) and Image Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_CSV = False\n",
    "CSV_PATH = Path('combined128.csv').absolute()\n",
    "CSV_IMAGE_COLUMN = 'image_path' #relative path of image inside IMG_FOLDER e.g. train/cat/10.jpg\n",
    "\n",
    "#test\n",
    "assert(os.path.isdir(CSV_PATH.parent))\n",
    "if (not os.path.isfile(CSV_PATH)) or OVERWRITE_CSV:\n",
    "    print(\"OVERWRITING CSV \")\n",
    "    from lib.prep import create_csv_with_image_paths\n",
    "    output = create_csv_with_image_paths(CSV_PATH, CSV_IMAGE_COLUMN, IMAGE_FOLDER, list(ATTRIBUTES.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Widget\n",
    "Widget loads subset (4 or so) images for user to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.widgets import MultilabelerWidget\n",
    "        \n",
    "mlw = MultilabelerWidget(csv_path = CSV_PATH, image_folder = IMAGE_FOLDER, image_column=CSV_IMAGE_COLUMN, attributes=ATTRIBUTES, width = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load labeled images into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {}\n",
    "for attribute in ATTRIBUTES:\n",
    "    dtype_dict[attribute]='category'\n",
    "\n",
    "df = pandas.read_csv(CSV_PATH,dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porches_df = df[df['steps_up']!=UNLABELED_TAG]\n",
    "porches_df = porches_df[porches_df['steps_up']!=IGNORE_TAG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai loading taken from\n",
    "https://gist.github.com/yang-zhang/ec071ae4775c2125595fd80f40efb0d6#file-multi-face-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.prep import LabelCls\n",
    "il = ImageList.from_df(df=porches_df, path='/', folder=IMAGE_FOLDER, cols = CSV_IMAGE_COLUMN)\n",
    "sil = il.split_by_rand_pct(0.4,2)\n",
    "lsil = sil.label_from_df(cols=list(ATTRIBUTES), label_cls=LabelCls, ATTRIBUTES=ATTRIBUTES)\n",
    "\n",
    "tfms = get_transforms(flip_vert=False, max_rotate= 10,xtra_tfms=[])\n",
    "for tfm in tfms:\n",
    "    for subtfm in tfm:\n",
    "        subtfm.use_on_y = False\n",
    "        \n",
    "lsil.transform(tfms, tfm_y=False)\n",
    "blsil = lsil.databunch(num_workers=4, bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blsil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid , save_image\n",
    "x, y = blsil.one_batch()\n",
    "Image(make_grid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify a save location for the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_EXPORT = Path(os.getcwd())/'classifier_export.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(input,target):\n",
    "    target = target.long()\n",
    "    one_hot_map = blsil.y.one_hot_map\n",
    "    input_split = []\n",
    "    losses = 0\n",
    "    for segment_endpoints in blsil.y.attribute_label_endpoints:\n",
    "        attribute_input = input[:,segment_endpoints[0]:segment_endpoints[1]]\n",
    "        attribute_target = target[:,segment_endpoints[0]:segment_endpoints[1]]\n",
    "        assert(torch.sum(attribute_target)==attribute_target.shape[0]), attribute_target\n",
    "        mask = (1-attribute_target[:,-1:])*(1-attribute_target[:,-2:-1])\n",
    "        masked_target = attribute_target[:,:] * mask\n",
    "        masked_input = attribute_input[:,:] * mask.float()\n",
    "        assert(torch.sum(masked_target)<=masked_target.shape[0]),masked_target\n",
    "        attribute_loss = None\n",
    "        if segment_endpoints[1]-segment_endpoints[0] > 1:\n",
    "            masked_target = masked_target.argmax(dim=1)\n",
    "            attribute_loss = F.cross_entropy(masked_input, masked_target)\n",
    "        else:\n",
    "            attribute_loss = F.l1_loss(attribute_input, attribute_target.unsqueeze(1))\n",
    "        losses+=(attribute_loss)\n",
    "    return  losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute_accuracy_metric:\n",
    "    \n",
    "    def __init__(self,attribute_idx):\n",
    "        print(attribute_idx)\n",
    "        self.segment_start, self.segment_end = blsil.y.attribute_label_endpoints[attribute_idx]\n",
    "        self.func = self.__call__\n",
    "        self.name = list(ATTRIBUTES)[attribute_idx]\n",
    "        \n",
    "        \n",
    "    def __call__(self, input_targs):\n",
    "        input_segment = input[self.segment_starts : self.segment_end]\n",
    "        target_segment = targs[self.segment_starts : self.segment_end]\n",
    "        return accuracy(input_segment, target_segment)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[Attribute_accuracy_metric(idx) for idx in range(len(blsil.y.attribute_label_endpoints))]\n",
    "metrics = []\n",
    "learn = cnn_learner(blsil, models.resnet18, metrics=metrics, pretrained=True, callback_fns=ShowGraph)\n",
    "learn.loss_func = myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sz, bs, lr):\n",
    "    learn.data=get_data(sz, bs)\n",
    "    learn.freeze()\n",
    "    learn.fit_one_cycle(5, slice(lr))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(5, slice(lr/20, lr/2), pct_start=0.1)\n",
    "    learn.save(f\"{target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.widgets import MultilabelerActiveLearningWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.widgets import MultilabelerActiveLearningWidget\n",
    "        \n",
    "mlw = MultilabelerActiveLearningWidget(learner = learn, classifier_export= CLASSIFIER_EXPORT, \n",
    "                         csv_path = CSV_PATH,\n",
    "                                       \n",
    "                         image_folder = IMAGE_FOLDER, \n",
    "                         image_column=CSV_IMAGE_COLUMN, \n",
    "                         attributes=ATTRIBUTES,\n",
    "                                       unlabeled_tag = UNLABELED_TAG,\n",
    "                         width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load classifier / train new classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load classifier + vae + modification vector for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "120.667px",
    "width": "237px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
